import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import random

def load_emnist():
    (train_data, test_data), info = tfds.load(
        'emnist/byclass',
        split=['train', 'test'],
        shuffle_files=True,
        as_supervised=True,
        with_info=True
    )
    return train_data, test_data, info

def preprocess(image, label):
    image = tf.transpose(image, [1, 0, 2])
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

train_data, test_data, info = load_emnist()

AUTOTUNE = tf.data.AUTOTUNE
batch_size = 128

train_data = train_data.map(preprocess, num_parallel_calls=AUTOTUNE)
train_data = train_data.shuffle(10000).batch(batch_size).prefetch(AUTOTUNE)

test_data = test_data.map(preprocess, num_parallel_calls=AUTOTUNE)
test_data = test_data.batch(batch_size).prefetch(AUTOTUNE)

model = models.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(62, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    train_data,
    epochs=5,
    validation_data=test_data,
    verbose=1
)

model.save("emnist_cnn_model.h5")

y_true = []
y_pred = []

for images, labels in test_data:
    preds = model.predict(images, verbose=0)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(labels.numpy())

print("\nClassification Report:")
print(classification_report(y_true, y_pred))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(15, 13))
sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

num_classes = len(cm)
correct = np.diag(cm)
total = np.sum(cm, axis=1)
incorrect = total - correct

plt.figure(figsize=(16, 6))
plt.bar(range(num_classes), incorrect, color='tomato', label='Misclassified')
plt.bar(range(num_classes), correct, bottom=incorrect, color='seagreen', label='Correct')
plt.xlabel('Class Index')
plt.ylabel('Number of Samples')
plt.title('Correct vs Misclassified Samples per Class')
plt.legend()
plt.tight_layout()
plt.show()

class_accuracy = correct / total
sorted_idx = np.argsort(class_accuracy)

plt.figure(figsize=(16, 6))
plt.bar(range(num_classes), class_accuracy[sorted_idx], color='royalblue')
plt.xticks(range(num_classes), sorted_idx, rotation=90)
plt.ylabel("Accuracy")
plt.title("Per-Class Accuracy (Sorted)")
plt.tight_layout()
plt.show()

misclassified = []

for x, y in test_data.unbatch().take(5000):
    logits = model(tf.expand_dims(x, 0), training=False)
    probs = tf.nn.softmax(logits)
    predicted = tf.argmax(probs, axis=1).numpy()[0]
    confidence = tf.reduce_max(probs).numpy()
    if predicted != y.numpy():
        misclassified.append((x.numpy(), y.numpy(), predicted, confidence))

misclassified = sorted(misclassified, key=lambda tup: -tup[3])[:12]

plt.figure(figsize=(14, 10))
for idx, (img, true_label, pred_label, conf) in enumerate(misclassified):
    plt.subplot(3, 4, idx+1)
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title(f"True: {true_label}, Pred: {pred_label}\nConf: {conf:.2f}")
    plt.axis('off')
plt.suptitle("Top Confident Misclassified Samples", fontsize=16)
plt.tight_layout()
plt.show()
